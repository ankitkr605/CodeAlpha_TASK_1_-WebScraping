{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfpoxuCymgwd",
        "outputId": "3c63b994-4ebe-4624-b4bf-da2c270987e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Libraries installed successfully!\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4 pandas\n",
        "\n",
        "print(\"Libraries installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "url = \"https://www.contextures.com/xlSampleData01.html\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "# Try different approaches to find the correct table\n",
        "data_table = None\n",
        "\n",
        "# Method 1: Find by summary attribute\n",
        "data_table = soup.find('table', attrs={'summary': 'Sample data for pivot tables'})\n",
        "\n",
        "# Method 2: If not found, try to find the table that contains actual data headers\n",
        "if data_table is None:\n",
        "    tables = soup.find_all('table')\n",
        "    for table in tables:\n",
        "        rows = table.find_all('tr')\n",
        "        if rows:\n",
        "            header_cells = rows[0].find_all(['th', 'td'])\n",
        "            headers = [cell.get_text(strip=True) for cell in header_cells]\n",
        "            # Look for the table with OrderDate, Region, Rep, Item columns\n",
        "            if any('OrderDate' in str(header) or 'Region' in str(header) or 'Rep' in str(header) for header in headers):\n",
        "                data_table = table\n",
        "                print(f\"Found data table using header matching\")\n",
        "                break\n",
        "\n",
        "# Method 3: If still not found, use the largest table\n",
        "if data_table is None:\n",
        "    tables = soup.find_all('table')\n",
        "    if tables:\n",
        "        # Find the table with the most rows\n",
        "        max_rows = 0\n",
        "        for table in tables:\n",
        "            row_count = len(table.find_all('tr'))\n",
        "            if row_count > max_rows:\n",
        "                max_rows = row_count\n",
        "                data_table = table\n",
        "        print(f\"Using largest table with {max_rows} rows\")\n",
        "\n",
        "if data_table:\n",
        "    rows = data_table.find_all('tr')\n",
        "\n",
        "    header_cells = rows[0].find_all(['th', 'td'])\n",
        "    headers = [cell.get_text(strip=True) for cell in header_cells]\n",
        "\n",
        "    print(f\"Found headers: {headers}\")\n",
        "\n",
        "    data = []\n",
        "    for row in rows[1:]:\n",
        "        cells = row.find_all(['th', 'td'])\n",
        "        if len(cells) == len(headers):\n",
        "            row_data = [cell.get_text(strip=True) for cell in cells]\n",
        "            data.append(row_data)\n",
        "\n",
        "    print(f\"Extracted {len(data)} data rows\")\n",
        "\n",
        "    if data and headers:\n",
        "        df = pd.DataFrame(data, columns=headers)\n",
        "\n",
        "        print(f\"\\nDataFrame shape: {df.shape}\")\n",
        "        print(\"\\nFirst 5 rows:\")\n",
        "        print(df.head())\n",
        "\n",
        "        # Create filtered DataFrame\n",
        "        columns_to_exclude = ['OrderDate', 'Region', 'Rep', 'Item', 'Units', 'UnitCost', 'Total']\n",
        "        df_filtered = df.drop(columns=columns_to_exclude, errors='ignore')\n",
        "\n",
        "        # Save both full and filtered datasets\n",
        "        df.to_csv(\"custom_dataset.csv\", index=False)\n",
        "        df_filtered.to_csv(\"custom_dataset_filtered.csv\", index=False)\n",
        "\n",
        "        print(f\"\\n Full DataFrame saved as 'custom_dataset.csv' at {os.path.abspath('custom_dataset.csv')}\")\n",
        "        print(f\" Filtered DataFrame saved as 'custom_dataset_filtered.csv' at {os.path.abspath('custom_dataset_filtered.csv')}\")\n",
        "        print(f\"\\nFiltered DataFrame shape: {df_filtered.shape}\")\n",
        "        print(\"\\nFiltered DataFrame (first 5 rows):\")\n",
        "        print(df_filtered.head())\n",
        "    else:\n",
        "        print(\"No valid data extracted from the table\")\n",
        "else:\n",
        "    print(\"Could not find any suitable data table on the webpage\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfALhpWWm1iI",
        "outputId": "c643b134-b7ac-4aa5-ebe4-36e0b464d9b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found data table using header matching\n",
            "Found headers: ['OrderDate', 'Region', 'Rep', 'Item', 'Units', 'UnitCost', 'Total']\n",
            "Extracted 43 data rows\n",
            "\n",
            "DataFrame shape: (43, 7)\n",
            "\n",
            "First 5 rows:\n",
            "   OrderDate   Region      Rep    Item Units UnitCost   Total\n",
            "0   1/6/2024     East    Jones  Pencil    95     1.99  189.05\n",
            "1  1/23/2024  Central   Kivell  Binder    50    19.99  999.50\n",
            "2   2/9/2024  Central  Jardine  Pencil    36     4.99  179.64\n",
            "3  2/26/2024  Central     Gill     Pen    27    19.99  539.73\n",
            "4  3/15/2024     West  Sorvino  Pencil    56     2.99  167.44\n",
            "\n",
            " Full DataFrame saved as 'custom_dataset.csv' at /content/custom_dataset.csv\n",
            " Filtered DataFrame saved as 'custom_dataset_filtered.csv' at /content/custom_dataset_filtered.csv\n",
            "\n",
            "Filtered DataFrame shape: (43, 0)\n",
            "\n",
            "Filtered DataFrame (first 5 rows):\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: [0, 1, 2, 3, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LTFebtrNngVo"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}